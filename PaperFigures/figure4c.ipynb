{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format ='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.random as random\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, grad, vmap\n",
    "from jax.example_libraries import optimizers\n",
    "\n",
    "import neural_tangents as nt\n",
    "from neural_tangents import stax\n",
    "\n",
    "from kernel_generalization import kernel_simulation as ker_sim\n",
    "from kernel_generalization import kernel_spectrum as ker_spec\n",
    "from kernel_generalization.utils import gegenbauer\n",
    "\n",
    "from matplotlib.cm import get_cmap\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "name = \"tab20\"\n",
    "cmap = get_cmap(name)  # type: matplotlib.colors.ListedColormap\n",
    "colors = cmap.colors \n",
    "savedir = \"/n/holyscratch01/pehlevan_lab/Lab/aatanasov/\"\n",
    "figdir = \"figures/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synth_data(p, dim, key):\n",
    "  x0 = random.normal(key, shape=(p,dim))\n",
    "  x = x0 / np.outer(np.linalg.norm(x0, axis=1), np.ones(dim))\n",
    "  return jnp.array(x)\n",
    "\n",
    "def pure_target_fn(X, beta, k):\n",
    "  dim = len(beta)\n",
    "  z = np.dot(X, beta)\n",
    "  y = gegenbauer.gegenbauer(z, k+1, dim)[k,:]\n",
    "  return jnp.array(y)[:, jnp.newaxis]\n",
    "\n",
    "def generate_train_data(p, beta, k, key):\n",
    "  emp_dim = 100\n",
    "  dim = len(beta)\n",
    "  key, emp_key = random.split(key)\n",
    "  X = generate_synth_data(p, dim, key)\n",
    "  y = pure_target_fn(X, beta, k)\n",
    "  return X, y\n",
    "\n",
    "def format_ps(pvals):\n",
    "  result = np.zeros(len(pvals), dtype=int)\n",
    "  for i, p in enumerate(pvals):\n",
    "    if p < 10:\n",
    "      result[i] = p + (p % 2)\n",
    "    elif p < 300:\n",
    "      result[i] = p + 10 - (p % 10)\n",
    "    elif p < 3000:\n",
    "      result[i] = p + 100 - (p % 100)\n",
    "    else:\n",
    "      result[i] = p + 1000 - p % 1000\n",
    "  return result     \n",
    "\n",
    "from functools import partial\n",
    "from jax import jvp, grad, jit\n",
    "\n",
    "def param_dist(params0, paramsf):\n",
    "  diff = norm(list(params0), list(paramsf))  \n",
    "  return jnp.sum(jnp.array(jax.tree_util.tree_leaves(diff)))\n",
    "\n",
    "def param_diff(params0, paramsf):\n",
    "  return jax.tree_map(lambda x, y: y-x, params0, paramsf)\n",
    "\n",
    "def jacobian_vector(apply_fn, X, params0, deltaparams):\n",
    "  f0 = lambda params: apply_fn(params, X)\n",
    "  return jvp(f0, [params0], [deltaparams])[1]\n",
    "\n",
    "def hessian_vector(apply_fn, X, params0, deltaparams):\n",
    "  f0 = lambda params: apply_fn(params, X)\n",
    "  df0 = lambda params: jvp(f0, [params], [deltaparams])[1]\n",
    "  return jvp(df0, [params0], [deltaparams])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_repeats = 20\n",
    "num_repeats_ker = num_repeats #150\n",
    "num_repeats_nn = num_repeats #5\n",
    "num_iter_nn = int(3e4)\n",
    "min_loss_nn = 1e-6\n",
    "\n",
    "## NN Hyperparameters\n",
    "lr = 0.008   # Only being used with adam\n",
    "layers = 2   # Hidden layers\n",
    "depth = layers + 1\n",
    "\n",
    "# For now we are actually not ensembling\n",
    "ensemble_size_list = [3]\n",
    "\n",
    "## Dimension, sample sizes, max eigenvalue mode to generate data\n",
    "dim = 10\n",
    "num_p = 15\n",
    "num_n = 7\n",
    "logpmin = .5\n",
    "lognmin = 1.5\n",
    "logpmax = np.log10(10000-1)\n",
    "lognmax = np.log10(5000)\n",
    "p_test = 2000\n",
    "kmax = 200\n",
    "\n",
    "num_repeats_eNTK = 3\n",
    "ensemble_size = 1\n",
    "\n",
    "# This is the sweep that we are going to be doing:\n",
    "pvals = np.logspace(logpmin, logpmax, num=num_p).astype('int')\n",
    "nvals = np.logspace(lognmin, lognmax, num=num_n).astype('int')\n",
    "pvals = format_ps(pvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synth_data(p, dim, key):\n",
    "  x0 = random.normal(key, shape=(p,dim))\n",
    "  x = x0 / np.outer(np.linalg.norm(x0, axis=1), np.ones(dim))\n",
    "  return jnp.array(x)\n",
    "\n",
    "def pure_target_fn(X, beta, k):\n",
    "  dim = len(beta)\n",
    "  z = np.dot(X, beta)\n",
    "  y = gegenbauer.gegenbauer(z, k+1, dim)[k,:]\n",
    "  return jnp.array(y)[:, jnp.newaxis]\n",
    "\n",
    "def generate_train_data(p, beta, k, key):\n",
    "  emp_dim = 100\n",
    "  dim = len(beta)\n",
    "  key, emp_key = random.split(key)\n",
    "  X = generate_synth_data(p, dim, key)\n",
    "  y = pure_target_fn(X, beta, k)\n",
    "  return X, y\n",
    "\n",
    "def format_ps(pvals):\n",
    "  result = np.zeros(len(pvals), dtype=int)\n",
    "  for i, p in enumerate(pvals):\n",
    "    if p < 10:\n",
    "      result[i] = p + (p % 2)\n",
    "    elif p < 300:\n",
    "      result[i] = p + 10 - (p % 10)\n",
    "    elif p < 3000:\n",
    "      result[i] = p + 100 - (p % 100)\n",
    "    else:\n",
    "      result[i] = p + 1000 - p % 1000\n",
    "  return result     \n",
    "\n",
    "from functools import partial\n",
    "from jax import jvp, grad, jit\n",
    "\n",
    "def param_dist(params0, paramsf):\n",
    "  diff = norm(list(params0), list(paramsf))  \n",
    "  return jnp.sum(jnp.array(jax.tree_util.tree_leaves(diff)))\n",
    "\n",
    "def param_diff(params0, paramsf):\n",
    "  return jax.tree_map(lambda x, y: y-x, params0, paramsf)\n",
    "\n",
    "def jacobian_vector(apply_fn, X, params0, deltaparams):\n",
    "  f0 = lambda params: apply_fn(params, X)\n",
    "  return jvp(f0, [params0], [deltaparams])[1]\n",
    "\n",
    "def hessian_vector(apply_fn, X, params0, deltaparams):\n",
    "  f0 = lambda params: apply_fn(params, X)\n",
    "  df0 = lambda params: jvp(f0, [params], [deltaparams])[1]\n",
    "  return jvp(df0, [params0], [deltaparams])[1]\n",
    "\n",
    "import neural_tangents as nt\n",
    "from neural_tangents import stax\n",
    "\n",
    "# Generate fully connected NN architecture\n",
    "def fully_connected(num_layers, width, sigma):\n",
    "  layers = []\n",
    "  for i in range(num_layers):\n",
    "    layers += [stax.Dense(width, W_std = sigma, b_std = 0), stax.Relu()]\n",
    "  layers += [stax.Dense(1, W_std=sigma, b_std=0)] \n",
    "  return stax.serial(*layers)\n",
    "\n",
    "def make_jax(params):\n",
    "  new_params = []\n",
    "  for i, layer in enumerate(params):\n",
    "    new_layer = []\n",
    "    for wnbs in layer:\n",
    "      new_wnbs = jnp.array(wnbs)\n",
    "      new_layer += [new_wnbs]\n",
    "    new_layer = tuple(new_layer)\n",
    "    new_params += [new_layer]\n",
    "  return new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_repeats = 20\n",
    "num_repeats_ker = num_repeats #150\n",
    "num_repeats_nn = num_repeats #5\n",
    "num_iter_nn = int(3e4)\n",
    "min_loss_nn = 1e-6\n",
    "\n",
    "## NN Hyperparameters\n",
    "lr = 0.008   # Only being used with adam\n",
    "layers = 2   # Hidden layers\n",
    "depth = layers + 1\n",
    "\n",
    "# For now we are actually not ensembling\n",
    "ensemble_size_list = [3]\n",
    "\n",
    "## Dimension, sample sizes, max eigenvalue mode to generate data\n",
    "dim = 10\n",
    "num_p = 15\n",
    "num_n = 5\n",
    "logpmin = .5\n",
    "lognmin = 1.5\n",
    "logpmax = np.log10(10000-1)\n",
    "lognmax = np.log10(1000)\n",
    "p_test = 2000\n",
    "kmax = 200\n",
    "\n",
    "num_repeats_eNTK = num_repeats_ker\n",
    "ensemble_size = 1\n",
    "\n",
    "# This is the sweep that we are going to be doing:\n",
    "pvals = np.logspace(logpmin, logpmax, num=num_p).astype('int')\n",
    "nvals = np.logspace(lognmin, lognmax, num=num_n).astype('int')\n",
    "pvals = format_ps(pvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d = 09\n",
      "eNTK0 error at width=1000, sigma=10.0 d=0\n",
      "d = 1\n",
      "eNTK0 error at width=1000, sigma=10.0 d=1\n",
      "d = 2\n",
      "d = 3\n",
      "d = 4\n",
      "eNTK0 error at width=1000, sigma=20 d=4\n",
      "d = 5\n",
      "eNTK0 error at width=1000, sigma=0.5 d=5\n",
      "eNTK0 error at width=1000, sigma=20 d=5\n",
      "d = 6\n",
      "eNTK0 error at width=1000, sigma=0.5 d=6\n",
      "d = 7\n",
      "eNTK0 error at width=1000, sigma=0.5 d=7\n",
      "eNTK0 error at width=1000, sigma=20 d=7\n",
      "d = 8\n",
      "eNTK0 error at width=1000, sigma=0.5 d=8\n",
      "eNTK0 error at width=1000, sigma=20 d=8\n",
      "d = 9\n",
      "eNTK0 error at width=1000, sigma=0.5 d=9\n",
      "eNTK0 error at width=1000, sigma=20 d=9\n",
      "d = 10\n",
      "eNTK0 error at width=421, sigma=0.1 d=10\n",
      "NN error at width=1000, sigma=0.1 d=10\n",
      "eNTK0 error at width=1000, sigma=0.1 d=10\n",
      "eNTK0 error at width=1000, sigma=0.5 d=10\n",
      "eNTK0 error at width=1000, sigma=20 d=10\n",
      "d = 11\n",
      "eNTK0 error at width=1000, sigma=0.5 d=11\n",
      "d = 12\n",
      "eNTK0 error at width=1000, sigma=0.1 d=12\n",
      "eNTK0 error at width=1000, sigma=20 d=12\n",
      "d = 13\n",
      "eNTK0 error at width=1000, sigma=0.1 d=13\n",
      "eNTK0 error at width=1000, sigma=20 d=13\n",
      "d = 14\n",
      "eNTK0 error at width=1000, sigma=0.1 d=14\n",
      "eNTK0 error at width=1000, sigma=0.5 d=14\n",
      "d = 15\n",
      "eNTK0 error at width=1000, sigma=0.5 d=15\n",
      "eNTK0 error at width=1000, sigma=20 d=15\n",
      "d = 16\n",
      "eNTK0 error at width=1000, sigma=0.5 d=16\n",
      "eNTK0 error at width=1000, sigma=1.0 d=16\n",
      "d = 17\n",
      "eNTK0 error at width=1000, sigma=0.5 d=17\n",
      "eNTK0 error at width=1000, sigma=1.0 d=17\n",
      "eNTK0 error at width=1000, sigma=10.0 d=17\n",
      "d = 18\n",
      "eNTK0 error at width=1000, sigma=0.1 d=18\n",
      "eNTK0 error at width=1000, sigma=0.5 d=18\n",
      "eNTK0 error at width=1000, sigma=1.0 d=18\n",
      "eNTK0 error at width=1000, sigma=10.0 d=18\n",
      "d = 19\n",
      "eNTK0 error at width=421, sigma=0.1 d=19\n",
      "NN error at width=1000, sigma=0.1 d=19\n",
      "eNTK0 error at width=1000, sigma=0.1 d=19\n",
      "eNTK0 error at width=1000, sigma=0.5 d=19\n",
      "eNTK0 error at width=1000, sigma=1.0 d=19\n",
      "eNTK0 error at width=1000, sigma=20 d=19\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "# Random keys\n",
    "init_key = random.PRNGKey(i_key)\n",
    "init_keys = random.split(init_key, max(num_repeats_nn, num_repeats_ker))\n",
    "\n",
    "# Crucially independent test key!! \n",
    "test_key = random.PRNGKey(0)\n",
    "beta_key, const_key, test_key = random.split(test_key, 3)\n",
    "\n",
    "# Data:\n",
    "train_sets = []\n",
    "for d_key in range(20):\n",
    "  print(f\"d = {d_key}\", end=\"\\r\")\n",
    "  data_key = random.PRNGKey(d_key)\n",
    "  train_key = random.split(data_key, len(pvals))\n",
    "  beta = generate_synth_data(1, dim, beta_key)[0,:]\n",
    "  y_const = np.sqrt(np.mean((generate_train_data(1000, beta, k, const_key)[1])**2))\n",
    "  Xs_train = []; ys_train = []\n",
    "  for i, p in enumerate(pvals):\n",
    "    X_train, y_train = generate_train_data(p, beta, k, train_key[i])\n",
    "    y_train = y_train/y_const\n",
    "    Xs_train += [X_train]\n",
    "    ys_train += [y_train]\n",
    "  train_sets += [(Xs_train, ys_train)]\n",
    "\n",
    "X_test, y_test = generate_train_data(p_test, beta, k, test_key)\n",
    "y_test = y_test/y_const\n",
    "test_set = (X_test, y_test)\n",
    "\n",
    "\n",
    "sigmas = [0.1, 0.5, 1.0, 10.0, 20]\n",
    "widths = nvals\n",
    "numK = 3\n",
    "numS = len(sigmas)\n",
    "numN = len(widths)\n",
    "\n",
    "numP = len(pvals)\n",
    "numE = 20\n",
    "numD = 20\n",
    "P_test = 2000\n",
    "\n",
    "NTK_errs = np.zeros(shape=(numS, numP, numD)) \n",
    "eNTK0_errs = np.zeros(shape=(numS, numN, numP, numE, numD)) \n",
    "yhats_eNTK0 = np.zeros(shape=(numS, numN, numP, numE, numD, P_test, 1)) \n",
    "NN_errs = np.zeros(shape=(numS, numN, numP, numE, numD))\n",
    "yhats_NN = np.zeros(shape=(numS, numN, numP, numE, numD, P_test, 1)) \n",
    "eNTK0_err_rat = np.zeros(shape=(numS, numN, numP, numE, numD))\n",
    "NN_err_rat = np.zeros(shape=(numS, numN, numP, numE, numD))\n",
    "\n",
    "\n",
    "for d in range(20):\n",
    "  print(f\"d = {d}\")\n",
    "  for i, sigma in enumerate(sigmas):\n",
    "    try: NTK_errs[i, :, d] = np.load(savedir+\"inf_err_L={}_k={}_s={:.2f}_d={}.npy\".format(depth, k, sigma, d))\n",
    "    except: print(f\"NTK error at sigma={sigma} d={d}\")\n",
    "    for j, width in enumerate(widths):    \n",
    "      try: \n",
    "        NN_errs[i, j, :, :, d] = np.load(savedir+\"gen_err_NN_N={}_L={}_k={}_s={:.2f}_d={}.npy\".format(width, depth, k, sigma, d))\n",
    "        yhats_NN[i, j, :, :, d, :, :] = np.load(savedir+\"yhats_NN_N={}_L={}_k={}_s={:.2f}_d={}.npy\".format(width, depth, k, sigma, d))      \n",
    "      except: print(f\"NN error at width={width}, sigma={sigma} d={d}\")\n",
    "      try: \n",
    "        eNTK0_errs[i, j, :, :, d] = np.load(savedir+\"gen_err_eNTK0_N={}_L={}_k={}_s={:.2f}_d={}.npy\".format(width, depth, k, sigma, d))\n",
    "        yhats_eNTK0[i, j, :, :, d, :, :] = np.load(savedir+\"yhats_eNTK0_N={}_L={}_k={}_s={:.2f}_d={}.npy\".format(width, depth, k, sigma, d))\n",
    "      except: print(f\"eNTK0 error at width={width}, sigma={sigma} d={d}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_to_nan(d):\n",
    "    array = np.array(d)\n",
    "    array[array == 0] = np.NaN\n",
    "    return array\n",
    "\n",
    "NTK_errs = zero_to_nan(NTK_errs)\n",
    "eNTK0_errs = zero_to_nan(eNTK0_errs)\n",
    "NN_errs = zero_to_nan(NN_errs);\n",
    "yhats_eNTK0 = zero_to_nan(yhats_eNTK0)\n",
    "yhats_NN = zero_to_nan(yhats_NN);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-7ab41d600557>:1: RuntimeWarning: Mean of empty slice\n",
      "  NN_errs_ens = np.nanmean((np.nanmean(yhats_NN[:, :, :, :, :, :, 0], axis=-3) - y_test[:, 0])**2, axis=-1)\n",
      "<ipython-input-10-7ab41d600557>:2: RuntimeWarning: Mean of empty slice\n",
      "  eNTK0_errs_ens = np.nanmean((np.nanmean(yhats_eNTK0[:, :, :, :, :, :, 0], axis=-3) - y_test[:, 0])**2, axis=-1)\n",
      "<ipython-input-10-7ab41d600557>:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  NN_err_rat = np.nanmean(NN_errs_ens, axis=-1)/np.nanmean(NN_errs, axis=(-1, -2))\n",
      "<ipython-input-10-7ab41d600557>:4: RuntimeWarning: Mean of empty slice\n",
      "  eNTK0_err_rat = np.nanmean(eNTK0_errs_ens, axis=-1)/np.nanmean(eNTK0_errs, axis=(-1, -2))\n"
     ]
    }
   ],
   "source": [
    "NN_errs_ens = np.nanmean((np.nanmean(yhats_NN[:, :, :, :, :, :, 0], axis=-3) - y_test[:, 0])**2, axis=-1)\n",
    "eNTK0_errs_ens = np.nanmean((np.nanmean(yhats_eNTK0[:, :, :, :, :, :, 0], axis=-3) - y_test[:, 0])**2, axis=-1)\n",
    "NN_err_rat = np.nanmean(NN_errs_ens, axis=-1)/np.nanmean(NN_errs, axis=(-1, -2))\n",
    "eNTK0_err_rat = np.nanmean(eNTK0_errs_ens, axis=-1)/np.nanmean(eNTK0_errs, axis=(-1, -2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ffcv)",
   "language": "python",
   "name": "ffcv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
